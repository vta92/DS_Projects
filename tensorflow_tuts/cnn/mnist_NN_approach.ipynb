{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data #tf has mnist for import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(train_dir=\"MNIST_data/\",one_hot=True)\n",
    "#we utilize the one_hot to have the data being imported, flattened and normalized. \n",
    "#28x28 pixels = 784 flattened data for each image\n",
    "#note that this does not have spatial information for us to use...hence it's inferior to cnn\n",
    "#the output is a special datatype/class, with its own unique methods that one might not always have the luxury to have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist) #special datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to view the sizes of dataset\n",
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this implies that there are 550k training samples, each with a matrix size of 784x1 being flattened from 28x28\n",
    "print(mnist.train.images.shape)\n",
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c419a1b70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c422399e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's view 1 of these images, let's pick the 5th one\n",
    "plt.imshow(mnist.train.images[4].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c42134e48>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAC/5JREFUeJzt3X/oXfV9x/Hney5RSIsoJdmXxCxd\nCWNDWDq+yCBhOMTgRiEGqTQIpmzs2z8qrLA/JoJUGIUy1m77q/ANhqbQpCmoM9S5toYxK0gwxlFt\nY1uR79IsIZlEiAWhmrz3x/dkfBu/90fuPfeem7yfDwj33vM5P94c8vp+zrnn3POJzERSPb/VdQGS\numH4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8V9dvT3FhEeDuhNGGZGcPMN1bPHxH3RcTPIuKt\niHh0nHVJmq4Y9d7+iLgJ+DlwL3AaeAXYk5k/7bOMPb80YdPo+e8C3srMtzPz18B3gF1jrE/SFI0T\n/o3AL1d8Pt1M+w0RsRARxyPi+BjbktSycb7wW+3Q4iOH9Zm5CCyCh/3SLBmn5z8N3LHi8ybgzHjl\nSJqWccL/CrA1Ij4ZEWuBzwFH2ilL0qSNfNifmR9GxCPA94GbgP2Z+ZPWKpM0USNf6htpY57zSxM3\nlZt8JF2/DL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqko\nwy8VZfilogy/VJThl4oy/FJRhl8qaqpDdOv6s2/fvr7tDz30UN/2HTt29Gw7ceLESDWpHfb8UlGG\nXyrK8EtFGX6pKMMvFWX4paIMv1TUWNf5I2IJeA+4BHyYmfNtFKXZsbS01Lf9lltu6du+devWnm1e\n5+9WGzf5/FlmvtPCeiRNkYf9UlHjhj+BH0TEqxGx0EZBkqZj3MP+7Zl5JiLWAz+MiDcz88WVMzR/\nFPzDIM2YsXr+zDzTvJ4HngHuWmWexcyc98tAabaMHP6IWBcRH7/yHtgJvNFWYZIma5zD/g3AMxFx\nZT0HM/PfW6lK0sSNHP7MfBv4oxZr0Qw6derUWMs//PDDPdsOHz481ro1Hi/1SUUZfqkowy8VZfil\nogy/VJThl4ry0d2aqA8++KDrEtSDPb9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFeV1fvW1e/fusZY/\ndOhQS5Wobfb8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1RUZOb0NhYxvY1pKNu2bevbfuzYsb7tFy9e\n7Nu+efPmnm3vv/9+32U1msyMYeaz55eKMvxSUYZfKsrwS0UZfqkowy8VZfilogb+nj8i9gOfAc5n\n5p3NtNuBw8AWYAl4MDPfnVyZmpSbb765b/uaNWv6tl++fLlvu9fyZ9cwPf83gfuumvYocDQztwJH\nm8+SriMDw5+ZLwIXrpq8CzjQvD8A3N9yXZImbNRz/g2ZeRageV3fXkmSpmHiz/CLiAVgYdLbkXRt\nRu35z0XEHEDzer7XjJm5mJnzmTk/4rYkTcCo4T8C7G3e7wWebaccSdMyMPwRcQh4Gfj9iDgdEX8F\nfBW4NyJ+AdzbfJZ0HRl4zp+Ze3o03dNyLerAAw880HUJ6oh3+ElFGX6pKMMvFWX4paIMv1SU4ZeK\ncoju4ubm5rouQR2x55eKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+\nqSjDLxVl+KWi/D3/DW7t2rV927ds2TLW+t98882xlld37Pmlogy/VJThl4oy/FJRhl8qyvBLRRl+\nqaiB1/kjYj/wGeB8Zt7ZTHsC+Gvgf5vZHsvMf5tUkRrdunXr+rZv3759rPW/8MILYy2v7gzT838T\nuG+V6f+UmduafwZfus4MDH9mvghcmEItkqZonHP+RyLixxGxPyJua60iSVMxavi/AXwK2AacBb7W\na8aIWIiI4xFxfMRtSZqAkcKfmecy81JmXgb2AXf1mXcxM+czc37UIiW1b6TwR8TKoV13A2+0U46k\naRnmUt8h4G7gExFxGvgycHdEbAMSWAK+MMEaJU3AwPBn5p5VJj85gVo0AXNzc4NnGsPzzz8/0fVr\ncrzDTyrK8EtFGX6pKMMvFWX4paIMv1SUj+6+wT3++ONjLf/cc8/1bX/ttdfGWr+6Y88vFWX4paIM\nv1SU4ZeKMvxSUYZfKsrwS0V5nf8Gd88994y1/Lvvvtu3/dKlS2OtX92x55eKMvxSUYZfKsrwS0UZ\nfqkowy8VZfilorzOfwPYsGFDz7Y1a9b0XTYi2i5H1wl7fqkowy8VZfilogy/VJThl4oy/FJRhl8q\nauB1/oi4A/gW8DvAZWAxM/8lIm4HDgNbgCXgwczs/+NvTcTi4mLPtltvvbXvspnZt/3gwYMj1aTZ\nN0zP/yHwt5n5B8CfAF+MiD8EHgWOZuZW4GjzWdJ1YmD4M/NsZp5o3r8HnAQ2AruAA81sB4D7J1Wk\npPZd0zl/RGwBPg0cAzZk5llY/gMBrG+7OEmTM/S9/RHxMeAp4EuZeXHYe8IjYgFYGK08SZMyVM8f\nEWtYDv63M/PpZvK5iJhr2ueA86stm5mLmTmfmfNtFCypHQPDH8td/JPAycz8+oqmI8De5v1e4Nn2\ny5M0KTHoUk9E7AB+BLzO8qU+gMdYPu//LrAZOAV8NjMvDFhX/41pVZs2berb/vLLL/ds27hxY99l\njx492rd9586dfdsH/f/R9GXmUOfkA8/5M/MloNfKxnsovKTOeIefVJThl4oy/FJRhl8qyvBLRRl+\nqSgf3X0dWL++/88mBl3L7+fAgQN9272Of+Oy55eKMvxSUYZfKsrwS0UZfqkowy8VZfilorzOf4N7\n6aWX+rYfOXJkSpVo1tjzS0UZfqkowy8VZfilogy/VJThl4oy/FJRA5/b3+rGfG6/NHHDPrffnl8q\nyvBLRRl+qSjDLxVl+KWiDL9UlOGXihoY/oi4IyL+IyJORsRPIuJvmulPRMT/RMR/Nf/+YvLlSmrL\nwJt8ImIOmMvMExHxceBV4H7gQeBXmfmPQ2/Mm3ykiRv2Jp+BT/LJzLPA2eb9exFxEhh9iBhJM+Ga\nzvkjYgvwaeBYM+mRiPhxROyPiNt6LLMQEccj4vhYlUpq1dD39kfEx4D/BL6SmU9HxAbgHSCBv2f5\n1OAvB6zDw35pwoY97B8q/BGxBvge8P3M/Poq7VuA72XmnQPWY/ilCWvthz0REcCTwMmVwW++CLxi\nN/DGtRYpqTvDfNu/A/gR8DpwuZn8GLAH2MbyYf8S8IXmy8F+67Lnlyas1cP+thh+afL8Pb+kvgy/\nVJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFDXyAZ8veAf57xedP\nNNNm0azWNqt1gbWNqs3afnfYGaf6e/6PbDzieGbOd1ZAH7Na26zWBdY2qq5q87BfKsrwS0V1Hf7F\njrffz6zWNqt1gbWNqpPaOj3nl9Sdrnt+SR3pJPwRcV9E/Cwi3oqIR7uooZeIWIqI15uRhzsdYqwZ\nBu18RLyxYtrtEfHDiPhF87rqMGkd1TYTIzf3GVm60303ayNeT/2wPyJuAn4O3AucBl4B9mTmT6da\nSA8RsQTMZ2bn14Qj4k+BXwHfujIaUkT8A3AhM7/a/OG8LTP/bkZqe4JrHLl5QrX1Gln683S479oc\n8boNXfT8dwFvZebbmflr4DvArg7qmHmZ+SJw4arJu4ADzfsDLP/nmboetc2EzDybmSea9+8BV0aW\n7nTf9amrE12EfyPwyxWfTzNbQ34n8IOIeDUiFrouZhUbroyM1Lyu77ieqw0cuXmarhpZemb23Sgj\nXreti/CvNprILF1y2J6Zfwz8OfDF5vBWw/kG8CmWh3E7C3yty2KakaWfAr6UmRe7rGWlVerqZL91\nEf7TwB0rPm8CznRQx6oy80zzeh54huXTlFly7sogqc3r+Y7r+X+ZeS4zL2XmZWAfHe67ZmTpp4Bv\nZ+bTzeTO991qdXW137oI/yvA1oj4ZESsBT4HHOmgjo+IiHXNFzFExDpgJ7M3+vARYG/zfi/wbIe1\n/IZZGbm518jSdLzvZm3E605u8mkuZfwzcBOwPzO/MvUiVhERv8dybw/Lv3g82GVtEXEIuJvlX32d\nA74M/CvwXWAzcAr4bGZO/Yu3HrXdzTWO3Dyh2nqNLH2MDvddmyNet1KPd/hJNXmHn1SU4ZeKMvxS\nUYZfKsrwS0UZfqkowy8VZfilov4PnSd/uQLKeUcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c419895f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to view in greyscale\n",
    "plt.imshow(mnist.train.images[4].reshape(28,28),cmap=\"gist_gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data input is already normalized between 0 and 1 with intensity of the pixels as the magnitude. Therefore it's there is no preprocessing techniques need to be done to use tensorflow with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32,shape = [None,784]) #we dont have the batch size for input yet, but each input will be a 784 array of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight initialization, it's not good to use just 0's but we'll stick to it for simplicity\n",
    "W = tf.Variable(tf.zeros([784,10])) #size of 10 for the 10 numbers features output. Input is 784 1d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.zeros([10])) #zero biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the computational graph\n",
    "y = tf.matmul(x,W) + b #watch for the matrix dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create loss function and Optimizer\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,10]) #10 outputs, we don't know the batch size. Must match up with x size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross entropy loss for multi labels. There's an average term from the wikipedia page. Hence, tf.reduce_mean()\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y)) #logits=prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after the loss, we need to find a way to optimize our model\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.3) #artitrary learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss=cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a session to run our computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9135\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #train the model for 1000 steps on training set using built in batch feeder from the mnist library\n",
    "    for steps in range(1000):\n",
    "        #we don't always have the luxury of retrieving batches from unique library like this\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size=50)\n",
    "        sess.run(train,feed_dict={x:batch_x, y_true:batch_y}) #recall our keys are the placeholders\n",
    "    \n",
    "    #to test the training model\n",
    "    matches = tf.equal(tf.argmax(y,1),tf.argmax(y_true,1)) #recal all these are placeholders above\n",
    "    #reduce_mean will find the average of our bool values array. However, we need to cast it to numerical first\n",
    "    accuracy = tf.reduce_mean(tf.cast(matches,dtype=tf.float32))\n",
    "    \n",
    "    #this refers all the way back to the previous run for our feed_dict. in this case, we need the test label and input\n",
    "    test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y_true:mnist.test.labels})\n",
    "    print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
