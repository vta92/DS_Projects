{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#following the tutorial of below to implement the cnn using tensorflow.\n",
    "#https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/02_Convolutional_Neural_Network.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the blog/github above for a general idea of how cnn functions.\n",
    "#watch hvass youtube video (the first 10 min) to explain how convolution, pooling work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pre-define the convolution layers\n",
    "#convolution layer 1, a total of 3x3 pixels filter with 16 filters in general -> this will give 16 output channels.\n",
    "#each output channel will be a result of the dot product between the filters (weight matrix) with the input\n",
    "#Defined by each stride length. Note no padding at the edges and pooling can reduce the image size after the convol layer\n",
    "filter_size1 = 3\n",
    "num_filters1 = 16\n",
    "\n",
    "#convolution layer 2\n",
    "filter_size2 = 3 #3x3 pixels\n",
    "num_filters2 = 20 #we'll lessen the number of filter for faster processing\n",
    "\n",
    "#dense layer, fully connected (after all the convolution stuff as input), this is middle layer prior to output \n",
    "fc_size = 980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#data will be in the flattened form of input (28x28 = 784 1d array)\n",
    "#target will be encoded in one_hot form: [0,0,0,0,0,1,0,0,0,0] = label #5.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets(train_dir=\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "10000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(data.train.num_examples)\n",
    "print(data.test.num_examples)\n",
    "print(data.validation.num_examples) #we won't be using this validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data dimensions defined for convience\n",
    "img_size = 28 #the number of pixels in each dimension of an image\n",
    "img_size_flat = 784 #28x28\n",
    "img_shape = (28,28) #height x width\n",
    "num_classes = 10 #10 outputs, 1 for each digit from 0 -> 9\n",
    "num_channels = 1 #grayscale, initial channel is only 1, we should have the same amount of channels as the first # of filters for the 2nd convo layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions for our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05)) #values with over 2 stdev will be truncated. Follow normal dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#should be y = x*W+b. Each filter will be dot prod. with the input -> scalar value, thus allowing to add a scalar bias.\n",
    "#therefore the bias should have the same size as our convo output channels\n",
    "def new_bias(length):\n",
    "    return tf.Variable(tf.constant(value=0.05, shape=[length])) #1d, peut-etre size of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpfer function for creating new Convolution Layer with the input of our tensor:\n",
    "1. Image number\n",
    "2. Y-axis size - 28 #depend on pooling & strides used, or padding for the 2nd convo input\n",
    "3. X-axis size - 28 #depend on pooling & strides used, or padding for the 2nd convo input\n",
    "4. Channel size - 1 for first layer input to convo layer, the second layer will be as many as the first filters we have chosen.\n",
    "\n",
    "If an image has 3 colors perhaps, we can also have 3 channels coming in the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as stated above, we have: 1-image number, 2-number of channels on first convo layer, 3-num_filters for the first convo\n",
    "#4-pooling or not (to reduce image size of the output, and retain significant details - maxpooling)\n",
    "def new_conv_layer(input, num_input_channels, filter_size, num_filters, use_pooling=True):\n",
    "    \n",
    "    #shape of the filter-weight for the convolution, formatted with Tensorflow API\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    \n",
    "    #weight matrices, or filters init\n",
    "    #this case, it's [784 x #of filters], we have [data set size x 784 input] and require an output equal to the #of filters \n",
    "    weights = new_weights(shape=shape)\n",
    "    \n",
    "    #bias matrix. output = x*W+b so B must be the same as the number of channels after the first filter here\n",
    "    biases = new_bias(length = num_filters)\n",
    "    \n",
    "    #Creating tensorflow operation for our convolution\n",
    "    #first stride = 1 (due to only 1 number image input, we don't want to skip any raw data input)\n",
    "    #second stride = y movement , let it be 1 ->shift 1 cell below\n",
    "    #third stride = x movement, let it be 1 ->shift 1 cell to the right\n",
    "    #forth = channel skipping. If it's 2 then we basically skilling channels. Maybe applicable for multi colors or 2nd layer\n",
    "    #however, first layer = 1 as we only have 1 channel, the grayscale. we'll also use 1 for 2nd convo layer\n",
    "    #padding=\"SAME\" will pad the edges of our images with zeros value \n",
    "    #to keep the output the same as input with strides(prior to pooling)\n",
    "    #automatically y=x*W for each filter, it should be a dot prod with single value, thus we need in bias at the end as scalar\n",
    "    layer = tf.nn.conv2d(input=input,filter=weights,strides = [1,1,1,1],padding=\"SAME\")\n",
    "    layer = layer+biases #add biases to each filter channel output\n",
    "    \n",
    "    if use_pooling == True:\n",
    "        #using 2x2 maxpooling to reduce the output size for each image of each channel\n",
    "        #note, no overlapping. this will also reduce our img size by [x/2 x y/2] after the first pooling (if padded to keep convo output the same)\n",
    "        #we use the same logic for number of input and channel size, we don't want to skip any.\n",
    "        #however, stepping of 2 for x-y for maxpooling as discussed.\n",
    "        layer = tf.nn.max_pool(value=layer,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    \n",
    "    #important, relu is usually executed before pooling, but relu(max_pool(x)) == max_pool(relu(x)) will retrieve the max value\n",
    "    #we can save all the relu work by just relu at the end. think about the function above, as relu(x) = 0 for x<0\n",
    "    #and relu(x) = x so we do not lose any info when x>0\n",
    "    layer = tf.nn.relu(layer) #activation function!\n",
    "    \n",
    "    #return the layer and weights (for plotting)\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function for flattening a layer\n",
    "#our convo layer output will be [img number, ysize,xsize,channel] and we need to compress this to 2d for fully conn. network\n",
    "\n",
    "def flatten_layer(layer): #input the convo layer\n",
    "    layer_shape = layer.get_shape() #get the input shape\n",
    "    #layer_shape will have the format of [num_images,img_height,img_width,num_channels]\n",
    "    \n",
    "    #to send into a fcc network, the features = img_height*img_width*num_channels\n",
    "    #we can calculate with tensorflow method\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    #the n means to infer, as the size of our data input (batch_size in our case), while keeping the other dim\n",
    "    #listed as the same: ie: numb_features need to be the same each time, but we dont know how many data we're using for the first dim\n",
    "    #in our case, -1 refers to the num_images; or our input batch\n",
    "    layer_flat = tf.reshape(layer,[-1,num_features])\n",
    "    \n",
    "    #result shape = [num_images,img_height*img_width*num_channels]\n",
    "    \n",
    "    return layer_flat,num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finally, a helper function for our fcc, this is just a 1 middle layer neural net from our prev flattened output\n",
    "def new_fc_layer(input,             #the prev layer\n",
    "                 num_inputs,        #number of inputs from prev layer\n",
    "                 num_outputs,       #number of outputs\n",
    "                 use_relu=True):    #reLu activation\n",
    "    \n",
    "    #creating weights and biases variables\n",
    "    # Y = X*weights + b, there are 9 outputs generally \n",
    "    weights = new_weights(shape=[num_inputs,num_outputs])\n",
    "    biases = new_bias(length = num_outputs)\n",
    "    \n",
    "    layer = tf.matmul(input,weights) + biases\n",
    "    if use_relu == True:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's run the model created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,img_size_flat],name=\"x\") #a 784 1d vector input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basically our convo layer needs a [num images, y pixel, x pixel, num of channels]. \n",
    "#-1 means the number of images will be inferred automatically\n",
    "x_image = tf.reshape(x,[-1,img_size,img_size,num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basically a 1-10 array with binary result\n",
    "y_true = tf.placeholder(tf.float32,shape=[None, num_classes],name=\"y_true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_cls = tf.argmax(y_true,axis=1) \n",
    "#return the index of the maximum value in the y_true array to induce out the correct solution\n",
    "#ie: [0,0,1,..,0] = 2 because of the index location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution layer #1\n",
    "#first input is a reshapped image of the 28x28 using 4d tensor as discussed above.\n",
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image,num_input_channels=num_channels, filter_size=filter_size1,\n",
    "                                           num_filters=num_filters1,use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_4:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1 #check out the shape. ? indicates we havent clarify the number of images for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second convo layer, which takes account from the 1st convo outputs\n",
    "#second input is the prev layer output of channels\n",
    "#the number of filters based on the first image will also determine the number of channels output for the 1st covo,\n",
    "#thus being the inputs of the second convo\n",
    "layer_conv2,weights_conv2 = new_conv_layer(input=layer_conv1,num_input_channels=num_filters1,filter_size=filter_size2,\n",
    "                                          num_filters=num_filters2,use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_5:0' shape=(?, 7, 7, 20) dtype=float32>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we need to flatten the output so we can use them as an input into our regular neural network\n",
    "layer_flat,num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_5:0' shape=(?, 980) dtype=float32>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat #the shape of layer_conv2 multiply together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features #obviously all these flattened data are the input!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_6:0' shape=(?, 600) dtype=float32>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the num_input needs to be about the same size as the total output from prev layer_flat\n",
    "layer_fc1 = new_fc_layer(input=layer_flat, num_inputs=fc_size, num_outputs=600, use_relu=True) #we'll use an arbitrary 100\n",
    "layer_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_19:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the number of input = number of output from prev layer, with the final output to use softmax LATER\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,num_inputs=600,num_outputs=num_classes,use_relu=False)\n",
    "layer_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we'll use softmax on the last layer output\n",
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred,axis=1) #return the index of which the highest prob. of the label occurs. our final solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y-true is defined above as a placeholder.\n",
    "#cost function defined. We'll optimize cross entropy to minimize the errors\n",
    "#THIS FUNCTION SUMS the errors\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc2,labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cost function average out to find the mean error \n",
    "cost = tf.reduce_mean(cross_entropy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimizer, let's use adam with smart gradient descent.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.0005)\n",
    "optimizer = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Performance measurements\n",
    "correct_pred = tf.equal(y_pred_cls,y_true_cls) \n",
    "#these are labels, not arrays. Ie: 5 vs. 2. They will be stored an array of [number of img] with true/false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,dtype=tf.float32)) \n",
    "#casting the boolean into 1/0 and average the entire dataset to find the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total number of iterations to train\n",
    "total_iterations = 0\n",
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations,total_iterations+num_iterations):\n",
    "        #as done prev in normal model, the API of mnist has its own methods to get the next batches for training\n",
    "        x_batch, y_true_batch = data.train.next_batch(batch_size=50)\n",
    "        \n",
    "        #put the batch into dict with proper names\n",
    "        feed_dict_train = {x:x_batch,y_true:y_true_batch}\n",
    "        sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            #calculate accuracy every 100 iterations\n",
    "            acc = sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "            msg = \"Optimization Iteration: {0: >6}, Training Accuracy: {1:>6.1%}\"\n",
    "            print(acc)\n",
    "            print(msg.format(i+1, acc))\n",
    "        \n",
    "    total_iterations += num_iterations\n",
    "    end_time = time.time()\n",
    "        \n",
    "    time_dif = end_time - start_time\n",
    "    print(\"time usage: \" + str(timedelta(seconds = int(round(time_dif)))))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.Session() as sess:\n",
    "#    sess.run(init)\n",
    "#    train_batch_size = 60\n",
    "    \n",
    "#    acc = sess.run(optimize(num_iterations=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86\n",
      "Optimization Iteration:      1, Training Accuracy:  86.0%\n",
      "0.98\n",
      "Optimization Iteration:    101, Training Accuracy:  98.0%\n",
      "0.96\n",
      "Optimization Iteration:    201, Training Accuracy:  96.0%\n",
      "1.0\n",
      "Optimization Iteration:    301, Training Accuracy: 100.0%\n",
      "1.0\n",
      "Optimization Iteration:    401, Training Accuracy: 100.0%\n",
      "0.96\n",
      "Optimization Iteration:    501, Training Accuracy:  96.0%\n",
      "0.98\n",
      "Optimization Iteration:    601, Training Accuracy:  98.0%\n",
      "1.0\n",
      "Optimization Iteration:    701, Training Accuracy: 100.0%\n",
      "0.98\n",
      "Optimization Iteration:    801, Training Accuracy:  98.0%\n",
      "0.96\n",
      "Optimization Iteration:    901, Training Accuracy:  96.0%\n",
      "time usage: 0:00:23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_iterations = 0 #need to reset value first\n",
    "optimize(num_iterations=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#need to find out how to resolve the accuracy issue of rounding decimals. However, we've done a decent job at getting started with the theory of cnn and how to implement a basic system with much higher accuracy than the normal DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
