{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#for image processing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = \"train/\"\n",
    "test_dir = \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAAMzklEQVR4nO2dSW+bxxnHh+Iritp3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\nqFkBEicrQP4HKu3/RnKRIngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x110365940>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading an example\n",
    "picture3 = image.load_img(train_dir+\"0a02cef73a1660adad8fc43b07fa9d23.jpg\", target_size=(100,100))\n",
    "picture3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I cannot see an individual cactus representation based off from these pictures. Our pixels dim = 32x32 from files, which is also very small. We'll just have to experience the process like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 2)\n",
      "1    0.750629\n",
      "0    0.249371\n",
      "Name: has_cactus, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  has_cactus\n",
       "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
       "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
       "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
       "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
       "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training df import\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "print(df.shape) #we have quite a bit of data, not too little.\n",
    "#The dataset isn't balanced, yet it's not too heavily leaning toward 1 class or the other. A normal CNN could still have\n",
    "#a decent result with this set, assuming that the differences will be distinct enough.\n",
    "print(df.has_cactus.value_counts(normalize=True))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list to hold the 4d image tensors data, the 1st python line gives error for too many open file.\n",
    "#X_pics = [image.load_img(train_dir+img_name,target_size=(32,32)) for img_name in df[\"id\"]]\n",
    "\n",
    "def load_imgs(train_dir,df):\n",
    "    img_list = []\n",
    "    for img in df[\"id\"]:\n",
    "        with open(os.path.join(train_dir, img), 'rb') as i:\n",
    "            img = image.load_img(i,target_size=(32,32))\n",
    "            img_list.append(img)\n",
    "    return img_list\n",
    "\n",
    "\n",
    "#return random indices from a df, particularly use to see random images\n",
    "def random_imgs(df,num_images,X_pics):\n",
    "    index_lst = df[\"id\"].sample(n=num_images).index\n",
    "    image_lst = []\n",
    "    for i in index_lst:\n",
    "        image_lst.append(X_pics[i])\n",
    "    return image_lst\n",
    "\n",
    "#cactus = random_imgs(df[df[\"has_cactus\"]==1],4,X_pics)\n",
    "#no_cactus = random_imgs(df[df[\"has_cactus\"] == 0],4,X_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'JpegImageFile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-887a5c3b8191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_pics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#for visualization only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_pics\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#tensor form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-887a5c3b8191>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_pics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#for visualization only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_pics\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#tensor form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/anaconda3/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[0;34m(img, data_format)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# or (channel, height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m# but original PIL image has format (width, height, channel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'JpegImageFile'"
     ]
    }
   ],
   "source": [
    "train_pics = load_imgs(train_dir,df) #for visualization only\n",
    "train = [np.array(image.img_to_array(i)) for i in train_pics] #tensor form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to pick random images for viewring from both labels (cactus, no cactus)\n",
    "cactus = random_imgs(df[df[\"has_cactus\"]==1],4,X_pics)\n",
    "no_cactus = random_imgs(df[df[\"has_cactus\"] == 0],4,X_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32 at 0x1C2955B908>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32 at 0x1C2848DD68>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32 at 0x1C2B864D68>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32 at 0x1C2B0C16D8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
