{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Number of Bike Rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17379, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals = pd.read_csv('bike_rental_hour.csv')\n",
    "print(bike_rentals.shape)\n",
    "bike_rentals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Count')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxWYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f429400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bike_rentals['cnt'].plot.hist(edgecolor=\"black\") #total number of bike rental, casual + registered\n",
    "plt.title(\"Distribution of Rental per Hour\")\n",
    "plt.xlabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnt           1.000000\n",
       "registered    0.972151\n",
       "casual        0.694564\n",
       "temp          0.404772\n",
       "atemp         0.400929\n",
       "hr            0.394071\n",
       "instant       0.278379\n",
       "yr            0.250495\n",
       "season        0.178056\n",
       "mnth          0.120638\n",
       "windspeed     0.093234\n",
       "workingday    0.030284\n",
       "weekday       0.026900\n",
       "holiday      -0.030927\n",
       "weathersit   -0.142426\n",
       "hum          -0.322911\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals.corr()['cnt'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better classify our feauture, instead of each hour, we do a categorical classification of the time of rental in a each, with the data being: morning, afternoon, evening, past-midnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert hour at rental to categorical like:1,2,3,4 (morning, afternoon,evening,night)\n",
    "def assign_label(row):\n",
    "    if (row >=6) and (row <12):\n",
    "        return 1 #le matin\n",
    "    elif (row >=12) and (row <18):\n",
    "        return 2 #l'apres midi\n",
    "    elif (row >=18) and (row < 24):\n",
    "        return 3 #evening\n",
    "    elif (row >=0) and (row < 6):\n",
    "        return 4 #la soiree\n",
    "    return\n",
    "\n",
    "bike_rentals['time_label'] = bike_rentals['hr'].apply(assign_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>time_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \\\n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16   \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40   \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32   \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13   \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1   \n",
       "\n",
       "   time_label  \n",
       "0           4  \n",
       "1           4  \n",
       "2           4  \n",
       "3           4  \n",
       "4           4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To help demonstrate the limited nature of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we then split the train/test set to 80/20\n",
    "train = bike_rentals.sample(frac=0.7)\n",
    "temp_index = bike_rentals.index.isin(train.index) #retrieving indices of our train set\n",
    "test = bike_rentals.iloc[~temp_index] #not in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17681.13550581253\n",
      "Mean:  189.51054852320675 Stdev:  182.03220578775012\n",
      "[-112.28786227  -85.5815239    63.99967514   55.80254073  131.09292013\n",
      "  124.55142094  135.85738437   69.96037323   89.19803239   90.38572423]\n",
      "1     40\n",
      "5      1\n",
      "6      2\n",
      "7      3\n",
      "13    94\n",
      "16    93\n",
      "17    67\n",
      "18    35\n",
      "20    36\n",
      "22    28\n",
      "Name: cnt, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "features = list(bike_rentals.columns)\n",
    "features.remove(\"cnt\") #our target\n",
    "#these are the columns that 'cnt' is derived from. \n",
    "#Different types of users who happen to rent bikes on that hour. They add up to'cnt' as we did before\n",
    "cols = ['casual','dteday','registered']\n",
    "for i in cols:\n",
    "    features.remove(i)\n",
    "    \n",
    "def linear_model(bike_rentals,features):\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(bike_rentals[features],bike_rentals[\"cnt\"],test_size=0.8,random_state=1)\n",
    "    model = LinearRegression()\n",
    "    model.fit(train[features],train['cnt'])\n",
    "    hypothesis = model.predict(test[features])\n",
    "\n",
    "    mse = np.mean((test['cnt'] - hypothesis)**2)\n",
    "    print(mse)\n",
    "    print(\"Mean: \",test['cnt'].mean(),\"Stdev: \",test['cnt'].std())\n",
    "    return mse, hypothesis\n",
    "\n",
    "mse1,lr1 = linear_model(bike_rentals,features)\n",
    "print(lr1[:10])\n",
    "print(test.cnt[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a high error, given the fact that our mean is only 188 in the 'cnt' column of test. As we have seen, it's unreasonable that some of the lower values of test carry a negative prediction on such a high swing. Actually, this is understandable since the top 3 parameters with high correlation to \"cnt\" are actually [\"casual\",\"registered\",\"temp\"]. Most other parameters after that don't carry as much weight as those. Items such as \"weekday\", \"month\" are actually better off as categorical,yet these don't carry as much meaning in Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model #2: Decision Tree and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2702.517050283919\n"
     ]
    }
   ],
   "source": [
    "#using decision tree to see if it's better than Linear Regression\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model2 = DecisionTreeRegressor(min_samples_leaf=8)\n",
    "model2.fit(train[features],train['cnt'])\n",
    "\n",
    "hypothesis2 = model2.predict(test[features])\n",
    "mse2 = np.mean((test['cnt'] - hypothesis2)**2)\n",
    "print(mse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree seems to be a lot better than Linear Regression. This probably is because the model isn't linear. Then we would expect the decision forest to be better. Also, many of the data aren't continous and aren't meant to be used with Linear Regression. Let's see if Random Forest Regressor will work better also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195.181199104038\n",
      "46.85276084825779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model3 = RandomForestRegressor(min_samples_leaf = 8) #same type of trees\n",
    "model3.fit(train[features],train['cnt'])\n",
    "\n",
    "hypothesis3 = model3.predict(test[features])\n",
    "mse3 = np.mean((test['cnt'] - hypothesis3)**2)\n",
    "print(mse3)\n",
    "print(mse3**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a single tree is prone to overfitting, it's good to see how much more we could've improved with random forest, which are less prone to overfitting. Let's put it together and try to tune the hyperparameters of our RandomForestRegressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([(1, 2018.6618009205986),\n",
       "             (2, 1932.611539180726),\n",
       "             (3, 1957.0718801757),\n",
       "             (4, 2037.3259689401712),\n",
       "             (5, 2039.7760492233888),\n",
       "             (6, 2055.8980803781883),\n",
       "             (7, 2291.558795565549),\n",
       "             (8, 2306.0376366435507),\n",
       "             (9, 2357.512235796835),\n",
       "             (10, 2438.5513336510244),\n",
       "             (11, 2422.0813846056976),\n",
       "             (12, 2537.6530013228216),\n",
       "             (13, 2599.1286874348225),\n",
       "             (14, 2592.0518821003056)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def rf_model(bike_rentals,features,min_leaf):\n",
    "    global train, test\n",
    "    result = OrderedDict()\n",
    "    for i in range(1,min_leaf):\n",
    "        model3 = RandomForestRegressor(min_samples_leaf=i) #same type of trees\n",
    "        model3.fit(train[features],train['cnt'])\n",
    "        \n",
    "        hypothesis3 = model3.predict(test[features])\n",
    "        metric = np.mean((test['cnt'] - hypothesis3)**2)\n",
    "        result[i] = metric\n",
    "    return result\n",
    "\n",
    "rf = rf_model(bike_rentals, features,15)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'MSE')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2352e5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(1,15)]\n",
    "y = []\n",
    "for key in x:\n",
    "    y.append(rf[key])\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"min leaf samples\")\n",
    "plt.ylabel(\"MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is surprising that small number of min leaf samples does not give into overfitting. Seems like the minimum leaf samples is not a hyperparameter we should play with. Let's do a matrix Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_features': array([1, 2, 3, 4, 5, 6, 7, 8, 9]), 'n_estimators': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14]), 'min_samples_leaf': array([1, 2, 3, 4, 5, 6, 7, 8, 9])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "#print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "#Grid_search\n",
    "'''\n",
    "rf = RandomForestRegressor()\n",
    "#we'll play with: maximum features to split at a nodes, the number of trees, and the minimum samples leaf for pruning\n",
    "hyper_params = { 'max_features':np.arange(1,10),'n_estimators':np.arange(5,15),'min_samples_leaf': np.arange(1,10)}\n",
    "rf_grid = GridSearchCV(rf, hyper_params,scoring=\"neg_mean_squared_error\",n_jobs=-1,cv = 5)\n",
    "rf_grid.fit(train[features],train[\"cnt\"])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv': 5, 'error_score': 'raise-deprecating', 'estimator__bootstrap': True, 'estimator__criterion': 'mse', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 'warn', 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False), 'fit_params': None, 'iid': 'warn', 'n_jobs': -1, 'param_grid': {'max_features': array([1, 2, 3, 4, 5, 6, 7, 8, 9]), 'n_estimators': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14]), 'min_samples_leaf': array([1, 2, 3, 4, 5, 6, 7, 8, 9])}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': 'warn', 'scoring': 'neg_mean_squared_error', 'verbose': 0}\n",
      "{'max_features': 9, 'min_samples_leaf': 1, 'n_estimators': 12}\n"
     ]
    }
   ],
   "source": [
    "#obtain best param of grid_search\n",
    "#print(rf_grid.get_params())\n",
    "#print(rf_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'cv': 5, 'error_score': 'raise-deprecating', 'estimator__bootstrap': True, 'estimator__criterion': 'mse', 'estimator__max_depth': None, 'estimator__max_features': 'auto', 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_impurity_split': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 'warn', 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
    "           oob_score=False, random_state=None, verbose=0, warm_start=False), 'fit_params': None, 'iid': 'warn', 'n_jobs': -1, 'param_grid': {'max_features': array([1, 2, 3, 4, 5, 6, 7, 8, 9]), 'n_estimators': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14]), 'min_samples_leaf': array([1, 2, 3, 4, 5, 6, 7, 8, 9])}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': 'warn', 'scoring': 'neg_mean_squared_error', 'verbose': 0}\n",
    "{'max_features': 9, 'min_samples_leaf': 1, 'n_estimators': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1892.3286917167457 RMSE:  43.500904493087795 Mean Count : 189.51054852320675\n"
     ]
    }
   ],
   "source": [
    "#derive from Grid_search above, which was commented out for efficiency\n",
    "def rf_best(bike_rentals,features):    \n",
    "    rf = RandomForestRegressor(min_samples_leaf=1, max_features=9, n_estimators=12) \n",
    "    #doens't seem to be too different from the default\n",
    "    rf.fit(train[features],train[\"cnt\"])\n",
    "    hypothesis = rf.predict(test[features])\n",
    "    metric = np.mean((test['cnt'] - hypothesis)**2)\n",
    "    return metric\n",
    "metric = rf_best(bike_rentals,features)\n",
    "print(\"MSE: \",metric,\"RMSE: \",np.sqrt(metric),\"Mean Count :\",test.cnt.mean()) #MSE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w9jErP/VagWTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a16d3db00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.47821250160699 1885.8697994803874\n"
     ]
    }
   ],
   "source": [
    "#Let's observe the variance and distribution of the metric.\n",
    "metric = []\n",
    "for i in range(30):\n",
    "    metric.append(rf_best(bike_rentals,features))\n",
    "    rmse = np.sqrt(metric)\n",
    "sns.kdeplot(metric)\n",
    "plt.title(\"Distribution of 30 RF runs\")\n",
    "plt.xlabel(\"MSE\")\n",
    "plt.show()\n",
    "print(np.std(metric), np.mean(metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the mean and stdev are roughly consistent (which is a good thing and doesn't seem to be overfitting), it is really interesting to see that our model doens't always give results in a manner close to a normal distribution. The mean MSE is about ~2000, which is not any meaningful improvement over our default model. However, it is greatly better than the Linear Regression (~17000 unoptimized).\n",
    "\n",
    "The RMSE of 45 means there's an average offset of 45 counts compared to the mean count of 190. This is due to the outliers we could observed in the histogram at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model #3: SV Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the processing intensity and the need to standardize our data (both nominal and continuous data), we will have to preprocess our data again for this algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
      "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
      "       'casual', 'registered', 'cnt', 'time_label'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "instant         int64\n",
       "dteday         object\n",
       "season          int64\n",
       "yr              int64\n",
       "mnth            int64\n",
       "hr              int64\n",
       "holiday         int64\n",
       "weekday         int64\n",
       "workingday      int64\n",
       "weathersit      int64\n",
       "temp          float64\n",
       "atemp         float64\n",
       "hum           float64\n",
       "windspeed     float64\n",
       "casual          int64\n",
       "registered      int64\n",
       "cnt             int64\n",
       "time_label      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "bike_rentals_norm = bike_rentals.copy()\n",
    "print(bike_rentals_norm.columns)\n",
    "bike_rentals_norm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>time_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \\\n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16   \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40   \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32   \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13   \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1   \n",
       "\n",
       "   time_label  \n",
       "0           4  \n",
       "1           4  \n",
       "2           4  \n",
       "3           4  \n",
       "4           4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to save training time and duplicated information from presenting in our model, we'll drop: instant(index), dteday(not trying to predict the future, just fitting current time), mnth(season encoded), hr (time_label has a division of 4 bins), holiday(semi represented in encoded in workingday) weekday (encoded in workingday), casual(cnt), registered(cnt).\n",
    "\n",
    "Afterward, we'll do one-hot encoding on: season, and time_label for various nominal categorical data.\n",
    "weathersit will be normalize to 1-4 as it suggests the good -> bad of weather in term of ordinal datatype. We expect no one to rent a bike when it's raining very heavily\n",
    "https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def season_spring(row):\n",
    "    if row == 1:\n",
    "        return 1\n",
    "    return 0\n",
    "def season_summer(row):\n",
    "    if row == 2:\n",
    "        return 1\n",
    "    return 0\n",
    "def season_autumn(row):\n",
    "    if row == 3:\n",
    "        return 1\n",
    "    return 0\n",
    "def season_winter(row):\n",
    "    if row == 4:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "bike_rentals_norm[\"season_sp\"] = bike_rentals_norm[\"season\"].apply(season_spring)\n",
    "bike_rentals_norm[\"season_su\"] = bike_rentals_norm[\"season\"].apply(season_summer)\n",
    "bike_rentals_norm[\"season_au\"] = bike_rentals_norm[\"season\"].apply(season_autumn)\n",
    "bike_rentals_norm[\"season_wi\"] = bike_rentals_norm[\"season\"].apply(season_winter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11413\n",
      "2     4544\n",
      "3     1419\n",
      "4        3\n",
      "Name: weathersit, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>...</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>time_label</th>\n",
       "      <th>season_sp</th>\n",
       "      <th>season_su</th>\n",
       "      <th>season_au</th>\n",
       "      <th>season_wi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit    ...       hum  windspeed  casual  registered  cnt  \\\n",
       "0           1    ...      0.81        0.0       3          13   16   \n",
       "1           1    ...      0.80        0.0       8          32   40   \n",
       "2           1    ...      0.80        0.0       5          27   32   \n",
       "3           1    ...      0.75        0.0       3          10   13   \n",
       "4           1    ...      0.75        0.0       0           1    1   \n",
       "\n",
       "   time_label  season_sp  season_su  season_au  season_wi  \n",
       "0           4          1          0          0          0  \n",
       "1           4          1          0          0          0  \n",
       "2           4          1          0          0          0  \n",
       "3           4          1          0          0          0  \n",
       "4           4          1          0          0          0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bike_rentals_norm[\"weathersit\"].value_counts()) #our expectation is well-defined\n",
    "bike_rentals_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>time_label</th>\n",
       "      <th>season_sp</th>\n",
       "      <th>season_su</th>\n",
       "      <th>season_au</th>\n",
       "      <th>season_wi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  yr  workingday  weathersit  temp   atemp   hum  windspeed  cnt  \\\n",
       "0       1   0           0           1  0.24  0.2879  0.81        0.0   16   \n",
       "1       1   0           0           1  0.22  0.2727  0.80        0.0   40   \n",
       "2       1   0           0           1  0.22  0.2727  0.80        0.0   32   \n",
       "3       1   0           0           1  0.24  0.2879  0.75        0.0   13   \n",
       "4       1   0           0           1  0.24  0.2879  0.75        0.0    1   \n",
       "\n",
       "   time_label  season_sp  season_su  season_au  season_wi  \n",
       "0           4          1          0          0          0  \n",
       "1           4          1          0          0          0  \n",
       "2           4          1          0          0          0  \n",
       "3           4          1          0          0          0  \n",
       "4           4          1          0          0          0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals_norm = bike_rentals_norm.drop(columns=[\"instant\",\"dteday\",\"mnth\",\"hr\",\"holiday\",\"weekday\",\"casual\",\"registered\"],axis=1)\n",
    "bike_rentals_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    4375\n",
       "3    4368\n",
       "1    4360\n",
       "4    4276\n",
       "Name: time_label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's observe the time_label to see if there's a definite pattern\n",
    "bike_rentals_norm.time_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_dawn(row):\n",
    "    if row == 1:\n",
    "        return 1\n",
    "    return 0\n",
    "def time_noon(row):\n",
    "    if row == 2:\n",
    "        return 1\n",
    "    return 0\n",
    "def time_evening(row):\n",
    "    if row == 3:\n",
    "        return 1\n",
    "    return 0\n",
    "def time_midnight(row):\n",
    "    if row == 4:\n",
    "        return 1\n",
    "    return 0\n",
    "bike_rentals_norm[\"time_dawn\"] = bike_rentals_norm.time_label.apply(time_dawn)\n",
    "bike_rentals_norm[\"time_noon\"] = bike_rentals_norm.time_label.apply(time_noon)\n",
    "bike_rentals_norm[\"time_evening\"] = bike_rentals_norm.time_label.apply(time_evening)\n",
    "bike_rentals_norm[\"time_midnight\"] = bike_rentals_norm.time_label.apply(time_midnight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yr</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>season_sp</th>\n",
       "      <th>season_su</th>\n",
       "      <th>season_au</th>\n",
       "      <th>season_wi</th>\n",
       "      <th>time_dawn</th>\n",
       "      <th>time_noon</th>\n",
       "      <th>time_evening</th>\n",
       "      <th>time_midnight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yr  workingday  weathersit  temp   atemp   hum  windspeed  cnt  season_sp  \\\n",
       "0   0           0           1  0.24  0.2879  0.81        0.0   16          1   \n",
       "1   0           0           1  0.22  0.2727  0.80        0.0   40          1   \n",
       "2   0           0           1  0.22  0.2727  0.80        0.0   32          1   \n",
       "3   0           0           1  0.24  0.2879  0.75        0.0   13          1   \n",
       "4   0           0           1  0.24  0.2879  0.75        0.0    1          1   \n",
       "\n",
       "   season_su  season_au  season_wi  time_dawn  time_noon  time_evening  \\\n",
       "0          0          0          0          0          0             0   \n",
       "1          0          0          0          0          0             0   \n",
       "2          0          0          0          0          0             0   \n",
       "3          0          0          0          0          0             0   \n",
       "4          0          0          0          0          0             0   \n",
       "\n",
       "   time_midnight  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals_norm = bike_rentals_norm.drop(columns=[\"season\",\"time_label\"])\n",
    "bike_rentals_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yr                 1.0000\n",
      "workingday         1.0000\n",
      "weathersit         4.0000\n",
      "temp               1.0000\n",
      "atemp              1.0000\n",
      "hum                1.0000\n",
      "windspeed          0.8507\n",
      "cnt              977.0000\n",
      "season_sp          1.0000\n",
      "season_su          1.0000\n",
      "season_au          1.0000\n",
      "season_wi          1.0000\n",
      "time_dawn          1.0000\n",
      "time_noon          1.0000\n",
      "time_evening       1.0000\n",
      "time_midnight      1.0000\n",
      "dtype: float64\n",
      "yr               0.00\n",
      "workingday       0.00\n",
      "weathersit       1.00\n",
      "temp             0.02\n",
      "atemp            0.00\n",
      "hum              0.00\n",
      "windspeed        0.00\n",
      "cnt              1.00\n",
      "season_sp        0.00\n",
      "season_su        0.00\n",
      "season_au        0.00\n",
      "season_wi        0.00\n",
      "time_dawn        0.00\n",
      "time_noon        0.00\n",
      "time_evening     0.00\n",
      "time_midnight    0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#model SVR here, afterward, do a neural network\n",
    "print(bike_rentals_norm.max())\n",
    "print(bike_rentals_norm.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['yr', 'workingday', 'temp', 'atemp', 'hum', 'windspeed', 'cnt',\n",
      "       'season_sp', 'season_su', 'season_au', 'season_wi', 'time_dawn',\n",
      "       'time_noon', 'time_evening', 'time_midnight', 'weathersit_norm'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "temp = scaler.fit_transform(bike_rentals_norm[[\"weathersit\"]])\n",
    "temp = temp.flatten()\n",
    "bike_rentals_norm[\"weathersit_norm\"] = temp\n",
    "bike_rentals_norm[\"weathersit_norm\"].value_counts()\n",
    "bike_rentals_norm.drop(\"weathersit\",axis=1, inplace=True)\n",
    "print(bike_rentals_norm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yr</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>season_sp</th>\n",
       "      <th>season_su</th>\n",
       "      <th>season_au</th>\n",
       "      <th>season_wi</th>\n",
       "      <th>time_dawn</th>\n",
       "      <th>time_noon</th>\n",
       "      <th>time_evening</th>\n",
       "      <th>time_midnight</th>\n",
       "      <th>weathersit_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yr  workingday  temp   atemp   hum  windspeed  cnt  season_sp  season_su  \\\n",
       "0   0           0  0.24  0.2879  0.81        0.0   16          1          0   \n",
       "1   0           0  0.22  0.2727  0.80        0.0   40          1          0   \n",
       "2   0           0  0.22  0.2727  0.80        0.0   32          1          0   \n",
       "3   0           0  0.24  0.2879  0.75        0.0   13          1          0   \n",
       "4   0           0  0.24  0.2879  0.75        0.0    1          1          0   \n",
       "\n",
       "   season_au  season_wi  time_dawn  time_noon  time_evening  time_midnight  \\\n",
       "0          0          0          0          0             0              1   \n",
       "1          0          0          0          0             0              1   \n",
       "2          0          0          0          0             0              1   \n",
       "3          0          0          0          0             0              1   \n",
       "4          0          0          0          0             0              1   \n",
       "\n",
       "   weathersit_norm  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = bike_rentals_norm.columns.tolist()\n",
    "features.remove(\"cnt\")\n",
    "bike_rentals_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recall\n",
    "'''\n",
    "#we then split the train/test set to 80/20\n",
    "train = bike_rentals.sample(frac=0.7)\n",
    "temp_index = bike_rentals.index.isin(train.index) #retrieving indices of our train set\n",
    "test = bike_rentals.iloc[~temp_index] #not in index\n",
    "'''\n",
    "temp_index = bike_rentals.index.isin(train.index)\n",
    "train_norm = bike_rentals_norm.iloc[temp_index]\n",
    "test_norm = bike_rentals_norm.iloc[~temp_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13068.02146452257"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SVR_model (train_norm, test_norm, features, target,kern):\n",
    "    svr_rbf = SVR(kernel=kern,C=1e3,gamma=0.5)\n",
    "    pred = svr_rbf.fit(train_norm[features],train_norm[target]).predict(test_norm[features])\n",
    "    mse = np.mean((test_norm[target] - pred)**2)\n",
    "    return mse\n",
    "\n",
    "rbf_mse = SVR_model(train_norm,test_norm,features,\"cnt\",\"rbf\")\n",
    "rbf_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19055.36740539059"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_mse = SVR_model(train_norm,test_norm,features,\"cnt\",\"linear\")\n",
    "linear_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13297.101847241596"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_mse = SVR_model(train_norm,test_norm,features,\"cnt\",\"poly\")\n",
    "poly_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have experienced above values with different kernels and C fudge factor, along with gamma. It turns out that the higher C value the better, and the higher gamma seems to give less MSE. We shall ignore both poly and linear kernels as they don't seem to give better results than the rbf kernel. Let's use grid search to look for the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#since we don\\'t have enough computing power to search, let\\'s just see if we ever will get close to the value of 2k with a rough search\\nSVR_search = SVR(kernel=\"rbf\")\\nhyper_params = { \\'C\\':[1e3,1e4,1e5],\\'gamma\\':[0.1,0.3,0.5,0.7]}\\nSVR_grid = GridSearchCV(SVR_search, hyper_params,scoring=\"neg_mean_squared_error\",n_jobs=-1, cv=5) #all cores\\nSVR_grid.fit(train_norm[features],train_norm[\"cnt\"])\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#since we don't have enough computing power to search, let's just see if we ever will get close to the value of 2k with a rough search\n",
    "SVR_search = SVR(kernel=\"rbf\")\n",
    "hyper_params = { 'C':[1e3,1e4,1e5],'gamma':[0.1,0.3,0.5,0.7]}\n",
    "SVR_grid = GridSearchCV(SVR_search, hyper_params,scoring=\"neg_mean_squared_error\",n_jobs=-1, cv=5) #all cores\n",
    "SVR_grid.fit(train_norm[features],train_norm[\"cnt\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(SVR_grid.best_params_)\\nprint(SVR_grid.grid_scores_)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(SVR_grid.best_params_)\n",
    "print(SVR_grid.grid_scores_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14056.076225621551"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the optimal result of our Grid_search here. Our results have very high standard dev, closer to 1/2 the mean value in general\n",
    "svr_rbf = SVR(kernel=\"rbf\",C=1e3,gamma=0.1)\n",
    "svr_pred = svr_rbf.fit(train_norm[features],train_norm[\"cnt\"]).predict(test_norm[features])\n",
    "svr_mse = np.mean((test_norm[\"cnt\"] - svr_pred)**2)\n",
    "svr_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not even come close to beating the Random Forest algorithm. Let's see what other complicated model that we can use to see improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model 4: Deep Learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since deep learning is good for tuning, and we have quite a few outliers/high stdev, it is high unlikely that the model will be an improvement over the used Random Forest algorithm. Regardless, with such a complicated model, we can build a system and see if it can predict better than the existing best case as an experiment (although a very time cosuming one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold Cross Validation with parameters tunning\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import callbacks\n",
    "\n",
    "history = History() #need to be defined first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_cnt = scaler.fit_transform(train_norm[[\"cnt\"]])\n",
    "#print(train_norm[features].columns)\n",
    "\n",
    "#we're going to use a relu activation function since our data is normalized to 0-1, hence having no negative value for algorithms such as sigmoid.\n",
    "def build_dnn():\n",
    "    dnn = Sequential() #sequence of layers\n",
    "    dnn.add(Dense(units=15,init=\"glorot_uniform\", activation=\"relu\", input_shape=(15,))) #15 inputs based on columns\n",
    "    dnn.add(Dropout(rate=0.05)) #dropout regularization of 5% rate of the neural nets \n",
    "    dnn.add(Dense(units=13, kernel_initializer=\"glorot_uniform\", activation=\"relu\")) #13 layers hidden\n",
    "    dnn.add(Dropout(rate=0.05))\n",
    "    dnn.add(Dense(units=13, kernel_initializer=\"glorot_uniform\", activation=\"relu\")) #13 layers hidden\n",
    "    dnn.add(Dropout(rate=0.05))\n",
    "    dnn.add(Dense(units=1, kernel_initializer=\"glorot_uniform\"))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True) #normal sgd\n",
    "    dnn.compile(loss='mean_squared_error',optimizer=sgd)\n",
    "    return dnn\n",
    "\n",
    "\n",
    "\n",
    "#cannot do a good search at this moment, no available computing power; but the idea stays the same\n",
    "#dnn_model = KerasRegressor(build_fn=build_dnn,verbose=0)\n",
    "#batch_size = [5] #fill up the sparse matrix\n",
    "#epochs = [30] #fill up the sparse matrix\n",
    "#param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "#grid = GridSearchCV(estimator=dnn_model, param_grid=param_grid,scoring='neg_mean_squared_error',cv=5)\n",
    "#grid_dnn = grid.fit(np.array(train_norm[features]), np.array(train_cnt)) #pandas input doesn't work. Need np array\n",
    "#matrix_results = grid_dnn.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10340 samples, validate on 1825 samples\n",
      "Epoch 1/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0190 - val_loss: 0.0289\n",
      "Epoch 2/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0159 - val_loss: 0.0249\n",
      "Epoch 3/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0153 - val_loss: 0.0266\n",
      "Epoch 4/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0149 - val_loss: 0.0251\n",
      "Epoch 5/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0146 - val_loss: 0.0250\n",
      "Epoch 6/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0144 - val_loss: 0.0244\n",
      "Epoch 7/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0143 - val_loss: 0.0240\n",
      "Epoch 8/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0142 - val_loss: 0.0244\n",
      "Epoch 9/200\n",
      "10340/10340 [==============================] - 10s - loss: 0.0140 - val_loss: 0.0288\n",
      "Epoch 10/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0141 - val_loss: 0.0244\n",
      "Epoch 11/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0140 - val_loss: 0.0227\n",
      "Epoch 12/200\n",
      "10340/10340 [==============================] - 11s - loss: 0.0140 - val_loss: 0.0236\n",
      "Epoch 13/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0140 - val_loss: 0.0237\n",
      "Epoch 14/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0139 - val_loss: 0.0303\n",
      "Epoch 15/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0138 - val_loss: 0.0223\n",
      "Epoch 16/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0136 - val_loss: 0.0247\n",
      "Epoch 17/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0138 - val_loss: 0.0235\n",
      "Epoch 18/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0139 - val_loss: 0.0235\n",
      "Epoch 19/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0137 - val_loss: 0.0268\n",
      "Epoch 20/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0138 - val_loss: 0.0224\n",
      "Epoch 21/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0137 - val_loss: 0.0246\n",
      "Epoch 22/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0137 - val_loss: 0.0252\n",
      "Epoch 23/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0135 - val_loss: 0.0249\n",
      "Epoch 24/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0136 - val_loss: 0.0241\n",
      "Epoch 25/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0135 - val_loss: 0.0235\n",
      "Epoch 26/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0136 - val_loss: 0.0240\n",
      "Epoch 27/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0135 - val_loss: 0.0238\n",
      "Epoch 28/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0134 - val_loss: 0.0234\n",
      "Epoch 29/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0134 - val_loss: 0.0226\n",
      "Epoch 30/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0134 - val_loss: 0.0228\n",
      "Epoch 31/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0133 - val_loss: 0.0266\n",
      "Epoch 32/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0134 - val_loss: 0.0222\n",
      "Epoch 33/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0132 - val_loss: 0.0242\n",
      "Epoch 34/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0133 - val_loss: 0.0233\n",
      "Epoch 35/200\n",
      "10340/10340 [==============================] - 10s - loss: 0.0132 - val_loss: 0.0226\n",
      "Epoch 36/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0133 - val_loss: 0.0213\n",
      "Epoch 37/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0131 - val_loss: 0.0243\n",
      "Epoch 38/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0132 - val_loss: 0.0232\n",
      "Epoch 39/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0130 - val_loss: 0.0233\n",
      "Epoch 40/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0132 - val_loss: 0.0230\n",
      "Epoch 41/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0132 - val_loss: 0.0244\n",
      "Epoch 42/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0132 - val_loss: 0.0221\n",
      "Epoch 43/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0133 - val_loss: 0.0235\n",
      "Epoch 44/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0132 - val_loss: 0.0219\n",
      "Epoch 45/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0133 - val_loss: 0.0228\n",
      "Epoch 46/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0131 - val_loss: 0.0233\n",
      "Epoch 47/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0131 - val_loss: 0.0220\n",
      "Epoch 48/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0131 - val_loss: 0.0220\n",
      "Epoch 49/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0130 - val_loss: 0.0228\n",
      "Epoch 50/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0129 - val_loss: 0.0221\n",
      "Epoch 51/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0130 - val_loss: 0.0217\n",
      "Epoch 52/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0132 - val_loss: 0.0215\n",
      "Epoch 53/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0131 - val_loss: 0.0211\n",
      "Epoch 54/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0132 - val_loss: 0.0215\n",
      "Epoch 55/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0132 - val_loss: 0.0222\n",
      "Epoch 56/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0130 - val_loss: 0.0212\n",
      "Epoch 57/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0129 - val_loss: 0.0229\n",
      "Epoch 58/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0130 - val_loss: 0.0228\n",
      "Epoch 59/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0131 - val_loss: 0.0220\n",
      "Epoch 60/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0131 - val_loss: 0.0227\n",
      "Epoch 61/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0129 - val_loss: 0.0225\n",
      "Epoch 62/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0130 - val_loss: 0.0242\n",
      "Epoch 63/200\n",
      "10340/10340 [==============================] - 10s - loss: 0.0130 - val_loss: 0.0218\n",
      "Epoch 64/200\n",
      "10340/10340 [==============================] - 10s - loss: 0.0130 - val_loss: 0.0225\n",
      "Epoch 65/200\n",
      "10340/10340 [==============================] - 10s - loss: 0.0129 - val_loss: 0.0213\n",
      "Epoch 66/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0128 - val_loss: 0.0237\n",
      "Epoch 67/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0127 - val_loss: 0.0208\n",
      "Epoch 68/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0127 - val_loss: 0.0212\n",
      "Epoch 69/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0128 - val_loss: 0.0217\n",
      "Epoch 70/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0129 - val_loss: 0.0210\n",
      "Epoch 71/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0129 - val_loss: 0.0225\n",
      "Epoch 72/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0128 - val_loss: 0.0218\n",
      "Epoch 73/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0128 - val_loss: 0.0212\n",
      "Epoch 74/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0129 - val_loss: 0.0218\n",
      "Epoch 75/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0129 - val_loss: 0.0231\n",
      "Epoch 76/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0128 - val_loss: 0.0212\n",
      "Epoch 77/200\n",
      "10340/10340 [==============================] - 10s - loss: 0.0129 - val_loss: 0.0219\n",
      "Epoch 78/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0128 - val_loss: 0.0220\n",
      "Epoch 79/200\n",
      "10340/10340 [==============================] - 17s - loss: 0.0127 - val_loss: 0.0214\n",
      "Epoch 80/200\n",
      "10340/10340 [==============================] - 12s - loss: 0.0127 - val_loss: 0.0244\n",
      "Epoch 81/200\n",
      "10340/10340 [==============================] - 11s - loss: 0.0129 - val_loss: 0.0214\n",
      "Epoch 82/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0126 - val_loss: 0.0217\n",
      "Epoch 83/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0128 - val_loss: 0.0210\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10340/10340 [==============================] - 11s - loss: 0.0128 - val_loss: 0.0205\n",
      "Epoch 85/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0127 - val_loss: 0.0217\n",
      "Epoch 86/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0129 - val_loss: 0.0214\n",
      "Epoch 87/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0126 - val_loss: 0.0223\n",
      "Epoch 88/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0127 - val_loss: 0.0221\n",
      "Epoch 89/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0233\n",
      "Epoch 90/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0128 - val_loss: 0.0226\n",
      "Epoch 91/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0127 - val_loss: 0.0207\n",
      "Epoch 92/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0128 - val_loss: 0.0238\n",
      "Epoch 93/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0126 - val_loss: 0.0204\n",
      "Epoch 94/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0126 - val_loss: 0.0233\n",
      "Epoch 95/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0126 - val_loss: 0.0211\n",
      "Epoch 96/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0207\n",
      "Epoch 97/200\n",
      "10340/10340 [==============================] - 12s - loss: 0.0127 - val_loss: 0.0218\n",
      "Epoch 98/200\n",
      "10340/10340 [==============================] - 14s - loss: 0.0126 - val_loss: 0.0207\n",
      "Epoch 99/200\n",
      "10340/10340 [==============================] - 10s - loss: 0.0126 - val_loss: 0.0207\n",
      "Epoch 100/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0126 - val_loss: 0.0219\n",
      "Epoch 101/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0127 - val_loss: 0.0247\n",
      "Epoch 102/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0127 - val_loss: 0.0205\n",
      "Epoch 103/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0126 - val_loss: 0.0219\n",
      "Epoch 104/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0127 - val_loss: 0.0216\n",
      "Epoch 105/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0127 - val_loss: 0.0213\n",
      "Epoch 106/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0217\n",
      "Epoch 107/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0127 - val_loss: 0.0207\n",
      "Epoch 108/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0213\n",
      "Epoch 109/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0126 - val_loss: 0.0210\n",
      "Epoch 110/200\n",
      "10340/10340 [==============================] - 10s - loss: 0.0127 - val_loss: 0.0219\n",
      "Epoch 111/200\n",
      "10340/10340 [==============================] - 11s - loss: 0.0127 - val_loss: 0.0216\n",
      "Epoch 112/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0125 - val_loss: 0.0207\n",
      "Epoch 113/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0124 - val_loss: 0.0211\n",
      "Epoch 114/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0125 - val_loss: 0.0208\n",
      "Epoch 115/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0126 - val_loss: 0.0208\n",
      "Epoch 116/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0125 - val_loss: 0.0217\n",
      "Epoch 117/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0127 - val_loss: 0.0217\n",
      "Epoch 118/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0206\n",
      "Epoch 119/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0128 - val_loss: 0.0207\n",
      "Epoch 120/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0126 - val_loss: 0.0213\n",
      "Epoch 121/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0126 - val_loss: 0.0212\n",
      "Epoch 122/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0218\n",
      "Epoch 123/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0232\n",
      "Epoch 124/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0126 - val_loss: 0.0218\n",
      "Epoch 125/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0225\n",
      "Epoch 126/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0216\n",
      "Epoch 127/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0126 - val_loss: 0.0217\n",
      "Epoch 128/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0126 - val_loss: 0.0210\n",
      "Epoch 129/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0125 - val_loss: 0.0249\n",
      "Epoch 130/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0126 - val_loss: 0.0243\n",
      "Epoch 131/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0125 - val_loss: 0.0218\n",
      "Epoch 132/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0125 - val_loss: 0.0211\n",
      "Epoch 133/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0126 - val_loss: 0.0210\n",
      "Epoch 134/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0125 - val_loss: 0.0220\n",
      "Epoch 135/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0125 - val_loss: 0.0271\n",
      "Epoch 136/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0123 - val_loss: 0.0209\n",
      "Epoch 137/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0125 - val_loss: 0.0207\n",
      "Epoch 138/200\n",
      "10340/10340 [==============================] - 12s - loss: 0.0125 - val_loss: 0.0209\n",
      "Epoch 139/200\n",
      "10340/10340 [==============================] - 10s - loss: 0.0125 - val_loss: 0.0205\n",
      "Epoch 140/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0214\n",
      "Epoch 141/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0217\n",
      "Epoch 142/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0124 - val_loss: 0.0211\n",
      "Epoch 143/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0207\n",
      "Epoch 144/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0240\n",
      "Epoch 145/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0208\n",
      "Epoch 146/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0125 - val_loss: 0.0206\n",
      "Epoch 147/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0215\n",
      "Epoch 148/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0126 - val_loss: 0.0215\n",
      "Epoch 149/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0213\n",
      "Epoch 150/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0125 - val_loss: 0.0207\n",
      "Epoch 151/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0124 - val_loss: 0.0210\n",
      "Epoch 152/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0125 - val_loss: 0.0211\n",
      "Epoch 153/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0209\n",
      "Epoch 154/200\n",
      "10340/10340 [==============================] - 11s - loss: 0.0125 - val_loss: 0.0208\n",
      "Epoch 155/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0124 - val_loss: 0.0211\n",
      "Epoch 156/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0124 - val_loss: 0.0209\n",
      "Epoch 157/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0227\n",
      "Epoch 158/200\n",
      "10340/10340 [==============================] - 11s - loss: 0.0124 - val_loss: 0.0204\n",
      "Epoch 159/200\n",
      "10340/10340 [==============================] - 11s - loss: 0.0124 - val_loss: 0.0231\n",
      "Epoch 160/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0124 - val_loss: 0.0218\n",
      "Epoch 161/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0124 - val_loss: 0.0208\n",
      "Epoch 162/200\n",
      "10340/10340 [==============================] - 13s - loss: 0.0124 - val_loss: 0.0209\n",
      "Epoch 163/200\n",
      "10340/10340 [==============================] - 13s - loss: 0.0125 - val_loss: 0.0211\n",
      "Epoch 164/200\n",
      "10340/10340 [==============================] - 10s - loss: 0.0124 - val_loss: 0.0214\n",
      "Epoch 165/200\n",
      "10340/10340 [==============================] - 11s - loss: 0.0124 - val_loss: 0.0208\n",
      "Epoch 166/200\n",
      "10340/10340 [==============================] - 11s - loss: 0.0124 - val_loss: 0.0206\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10340/10340 [==============================] - 8s - loss: 0.0125 - val_loss: 0.0207\n",
      "Epoch 168/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0124 - val_loss: 0.0208\n",
      "Epoch 169/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0220\n",
      "Epoch 170/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0215\n",
      "Epoch 171/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0124 - val_loss: 0.0212\n",
      "Epoch 172/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0126 - val_loss: 0.0211\n",
      "Epoch 173/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0221\n",
      "Epoch 174/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0210\n",
      "Epoch 175/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0229\n",
      "Epoch 176/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0124 - val_loss: 0.0206\n",
      "Epoch 177/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0124 - val_loss: 0.0221ss:\n",
      "Epoch 178/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0122 - val_loss: 0.0207\n",
      "Epoch 179/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0122 - val_loss: 0.0209\n",
      "Epoch 180/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0210\n",
      "Epoch 181/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0206\n",
      "Epoch 182/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0205\n",
      "Epoch 183/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0123 - val_loss: 0.0205\n",
      "Epoch 184/200\n",
      "10340/10340 [==============================] - 11s - loss: 0.0124 - val_loss: 0.0212\n",
      "Epoch 185/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0218\n",
      "Epoch 186/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0122 - val_loss: 0.0217\n",
      "Epoch 187/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0206\n",
      "Epoch 188/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0123 - val_loss: 0.0213\n",
      "Epoch 189/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0123 - val_loss: 0.0206\n",
      "Epoch 190/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0228\n",
      "Epoch 191/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0214\n",
      "Epoch 192/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0122 - val_loss: 0.0217\n",
      "Epoch 193/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0207\n",
      "Epoch 194/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0123 - val_loss: 0.0221\n",
      "Epoch 195/200\n",
      "10340/10340 [==============================] - 11s - loss: 0.0123 - val_loss: 0.0223\n",
      "Epoch 196/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0124 - val_loss: 0.0206\n",
      "Epoch 197/200\n",
      "10340/10340 [==============================] - 7s - loss: 0.0123 - val_loss: 0.0213\n",
      "Epoch 198/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0214\n",
      "Epoch 199/200\n",
      "10340/10340 [==============================] - 9s - loss: 0.0123 - val_loss: 0.0208\n",
      "Epoch 200/200\n",
      "10340/10340 [==============================] - 8s - loss: 0.0123 - val_loss: 0.0212\n"
     ]
    }
   ],
   "source": [
    "#print(matrix_results)\n",
    "#use the best result we have as parameters. We can't afford high epochs and low batch size.\n",
    "best_dnn_model = KerasRegressor(build_fn=build_dnn, epochs=200, batch_size=5,verbose=1,validation_split=0.15) #7kfolds\n",
    "history = best_dnn_model.fit(np.array(train_norm[features]),np.array(train_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the listed val_loss, it's hard to argue that it's either noise or we've been overfitting/plateauing with the current hyperparameters. Due to the resources available, we'll just demonstrate if the DNN will perform better than the Random Forest algorithm (this is very unlikely since our data has such a high variation, and neural networks are best used to tune in values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c41269b38>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a16d52978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_dnn_model.model.save_weights('dnn_weight.h5') #need to call model attribute again due to the cross_val above\n",
    "epochs_losses = history.history[\"loss\"]\n",
    "\n",
    "plt.plot([i for i in range(0,200)],epochs_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5190/5214 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.02829242, 0.03275446, 0.06231555, ..., 0.13890831, 0.14612903,\n",
       "       0.13229565], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_pred = best_dnn_model.predict(np.array(test_norm[features]))\n",
    "dnn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's inverse transform back the \"cnt_norm\" values for mse evaluation relative to the test set\n",
    "dnn_pred = np.reshape(dnn_pred,(-1,1)) #reshape for inverse transform\n",
    "#test_pred2.shape\n",
    "dnn_pred = scaler.inverse_transform(dnn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN MSE:  12749.096408160918 \n",
      " DNN RMSE:  112.91189666355321\n"
     ]
    }
   ],
   "source": [
    "dnn_pred\n",
    "dnn_mse = np.mean((dnn_pred[:,0] - test_norm[\"cnt\"])**2)\n",
    "print(\"DNN MSE: \",dnn_mse, \"\\n\", \"DNN RMSE: \",dnn_mse**0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusion: As expected, it's not anything better than the SVR. There are just too much outliers/variation in our data to begin with. It looks like the ~2000 MSE value from Random Forest is the best we can use. Complicated models like SVR and DNN are not neccessarily always better. Further hyperparameters are unlikely to bring that 5x MSE threshold down unless we mistrained our data horrendeously.\n",
    "Another possibility for the poor training might've stemmed from poorly chosen features for both the SVR and the DNN. It is however unavoidable since we needed to do encoding on some of the parameters and normalize them to make sure our loss functions can converge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
